---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# gsedread

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
<!-- badges: end -->

The goal of gsedread is to read validation data of the project Global Scales for Early Development (GSED).

## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
install.packages("remotes")
remotes::install_github("d-score/gsedread")
```

## Example

You need access to the WHO SharePoint site and sync the data to a local OneDrive. In the file `.Renviron` in your home directory add a line specifying the location of your synced OneDrive, e.g.,

```
ONEDRIVE_GSED='/Users/username/Library/CloudStorage/OneDrive-Sharedlibraries-WorldHealthOrganization/CAVALLERA, Vanessa - GSED Validation 2021_phase I'
```

After setting the environmental variable `ONEDRIVE_GSED`, restart R, and manually check whether you are able to read the OneDrive directory.

```{r}
dir(Sys.getenv("ONEDRIVE_GSED"))
```

The following commands reads all SF data from `GSED Final Collated Phase 1 Data Files 18_05_22` directory and returns a tibble with one record per administration.

```{r read_sf}
library(gsedread)
data <- read_sf()
dim(data)
```

Count the number of records per file:

```{r}
table(data$file)
```

## Operations

The package reads and processes GSED data. It does not store data. The `read_sf()` function takes the following actions:

1. Constructs the paths to the files OneDrive sync file;
2. Reads all specified datasets in a list;
3. Internally specifies the desired format for each column;
4. Specifies the available date and data-time formats per file;
5. Recodes empty, `NA`, `-8888`, `-8,888.00` and `-9999` values as `NA`;
6. Repairs problems with mixed data-time formats in the adaptive Pakistan data;
7. Stacks the datasets to one tibble with an extra column called `file`.
