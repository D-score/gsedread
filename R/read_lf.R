#' Read lf data
#'
#' @param type Character, either "fixed" or "adaptive"
#' @param onedrive Character, the location of the local OneDrive sync
#' @param path Character, path name within the OneDrive
#' @param verbose Logical. Print diagnostic info? Defaults to `FALSE`.
#' @param progress Logical. Show progress in interactive session. Default to `FALSE`.
#' @param warnings Logical. Show warnings generated by `readr::read_csv()`.
#' Defaults to `TRUE`.
#' @return A tibble with the original data and one new column named `file`
#' containing the original file name. If `type == "fixed"` a tibble with 159
#' columns, with one test administration per row. If `type == "adaptive"`, a tibble
#' with 14 columns, with one item administration per row.
#' @examples
#' \dontrun{
#' # assuming environmental variable ONEDRIVE_GSED has been set
#' d <- read_lf()
#' dim(d)
#' }
#' @export
read_lf <- function(type = c("fixed", "adaptive"),
                    onedrive = Sys.getenv("ONEDRIVE_GSED"),
                    path = "GSED Final Collated Phase 1 Data Files 18_05_22",
                    verbose = FALSE,
                    progress = FALSE,
                    warnings = TRUE) {
  if (nchar(onedrive) == 0L) {
    stop("Environmental variable ONEDRIVE_GSED not set.", call. = FALSE)
  }
  type <- match.arg(type)

  if (type == "fixed") {
    return(read_lf_fixed(onedrive, path, verbose, progress, warnings))
  } else {
    return(read_lf_adaptive(onedrive, path, verbose, progress, warnings))
  }
}

read_lf_fixed <- function(onedrive, path, verbose, progress, warnings) {
  # hardcode fixed lf files names
  files_fixed <- c(
    "tan/tza-lf-2021-11-01.csv",
    "tan/tza_lf_predictive_10_05_2022.csv",
    "tan/tza_lf_new_enrollment_10_05_2022.csv",
    "ban/ban-lf-2021-11-03.csv",
    "ban/ban_lf_predictive_17_05_2022.csv",
    "ban/ban_lf_new_enrollment_17_05_2022.csv",
    "pak/pak_lf_2022_05_17.csv",
    "pak/pak_lf_predictive_2022_05_17.csv",
    "pak/pak_lf_new_enrollment_2022_05_17.csv"
  )

  # read
  files <- file.path(onedrive, path, files_fixed)
  data <- vector(mode = "list", length = length(files))
  nm <- tolower(gsub("-", "_", basename(files)))
  names(data) <- unlist(lapply(strsplit(nm, split = "\\."), `[`, 1L))
  date_formats <- c(
    "%Y-%m-%d", "%d-%m-%Y", "%d-%m-%Y",
    "%d/%m/%Y", "%d/%m/%Y", "%d/%m/%Y",
    "%m/%d/%Y", "%m/%d/%Y", "%m/%d/%Y"
  )

  for (i in 1:length(files)) {
    spec <- define_col("lf", "fixed", date_formats[i])
    if (!warnings) {
      suppressWarnings(
        data[[i]] <- readr::read_csv(files[i],
                                     col_types = spec,
                                     na = c("", "NA", "-8888", "-8,888.00", "-9999"),
                                     show_col_types = verbose,
                                     progress = progress)
      )
    } else {
      data[[i]] <- readr::read_csv(files[i],
                                   col_types = spec,
                                   na = c("", "NA", "-8888", "-8,888.00", "-9999"),
                                   show_col_types = verbose,
                                   progress = progress)
    }
  }

  # bind
  # remove orphan records without a GSED_ID
  data %>%
    bind_rows(.id = "file") %>%
    filter(!is.na(.data$GSED_ID))
}

read_lf_adaptive <- function(onedrive, path, verbose, progress, warnings) {

  # hardcode adaptive lf files names
  files_adaptive <- c(
    "tan/tza_lf_adaptive_10_05_2022.csv",
    "tan/tza_lf_new_adaptive_10_05_2022.csv",
    "ban/ban_lf_adaptive_17_05_2022.csv",
    "ban/ban_lf_new_adaptive_17_05_2022.csv",
    "pak/pak_lf_adaptive_2022_05_17.csv",
    "pak/pak_lf_new_adaptive_2022_05_17.csv"
  )
  files <- file.path(onedrive, path, files_adaptive)
  data <- vector(mode = "list", length = length(files))
  nm <- tolower(gsub("-", "_", basename(files)))
  names(data) <- unlist(lapply(strsplit(nm, split = "\\."), `[`, 1L))
  date_formats <- c(
    "%d-%m-%Y", "%d-%m-%Y",
    "%d-%m-%Y", "%d/%m/%Y",
    "%m/%d/%Y", "%m/%d/%Y"
  )
  datetime_formats <- c(
    "%d-%m-%Y %H:%M:%S", "%d-%m-%Y %H:%M:%S",
    "%d-%m-%Y %H:%M:%S", "%d/%m/%Y %H:%M",
    "%d-%m-%Y %H:%M:%S", "%d-%m-%Y %H:%M:%S"
  )
  for (i in 1:length(files)) {
    spec <- define_col("lf", "adaptive", date_formats[i],
                       datetime_format = datetime_formats[i]
    )
    if (!warnings) {
      suppressWarnings(
        data[[i]] <- readr::read_csv(files[i],
                                     col_types = spec,
                                     na = c("", "NA", "-8888", "-8,888.00", "-9999"),
                                     show_col_types = verbose,
                                     progress = progress)
      )
    } else {
      data[[i]] <- readr::read_csv(files[i],
                                   col_types = spec,
                                   na = c("", "NA", "-8888", "-8,888.00", "-9999"),
                                   show_col_types = verbose,
                                   progress = progress)

    }
  }

  # repair mixed time stamp format in pak_lf_adaptive_2022_05_17 and
  # pak_lf_new_adaptive_2022_05_17 (about 15% of the values).
  for (i in 5:6) {
    spec <- define_col("lf", "adaptive", date_formats[i],
                       datetime_format = "%m/%d/%Y %H:%M"
    )
    if (!warnings) {
      suppressWarnings(
        tmp <- readr::read_csv(files[i],
                               col_types = spec,
                               na = c("", "NA", "-8888", "-8,888.00", "-9999"),
                               show_col_types = verbose)
      )
    } else {
      tmp <- readr::read_csv(files[i],
                             col_types = spec,
                             na = c("", "NA", "-8888", "-8,888.00", "-9999"),
                             show_col_types = verbose)
    }
    z <- data[[i]]$Ma_LF_timestamp
    z[is.na(z)] <- tmp$Ma_LF_timestamp[!is.na(tmp$Ma_LF_timestamp)]
    data[[i]]$Ma_LF_timestamp <- z
  }

  # bind
  # remove orphan records without a GSED_ID
  data %>%
    bind_rows(.id = "file") %>%
    filter(!is.na(.data$GSED_ID))
}
